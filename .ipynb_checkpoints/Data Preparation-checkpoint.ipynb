{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "352fb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import gensim\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import tika\n",
    "import re\n",
    "import docx\n",
    "from spacy.language import Language\n",
    "from tika import parser\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8247d6f",
   "metadata": {},
   "source": [
    "# Function to load Default spacy nlp model and starting the tika server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27f59d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDefaultNLP(is_big: bool = True):\n",
    "    \"\"\"\n",
    "    Function to load the default SpaCy nlp model into nlp\n",
    "    :Input is_big: if True, uses a large vocab set, else a small one\n",
    "    :returns: nlp: a SpaCy nlp model\n",
    "    \"\"\"\n",
    "\n",
    "    @Language.component(\"segment_on_newline\")\n",
    "    def segment_on_newline(doc):\n",
    "        for token in doc[:-1]:\n",
    "            if token.text.endswith(\"\\n\"):\n",
    "                doc[token.i + 1].is_sent_start = True\n",
    "        return doc\n",
    "\n",
    "    if is_big:\n",
    "        nlp = spacy.load(\"en_core_web_lg\")\n",
    "    else:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    Language.component(\"segment_on_newline\",func=segment_on_newline)\n",
    "    nlp.add_pipe(\"segment_on_newline\",before=\"parser\")\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06ddd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x0000014EABB76940>\n"
     ]
    }
   ],
   "source": [
    "nlp = loadDefaultNLP(False)\n",
    "tika.initVM()\n",
    "from tika import parser\n",
    "print(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401f312",
   "metadata": {},
   "source": [
    "# Get PDF/Doc names from the input directories where resumes are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f87b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDocumentsRecursive(base_dir):\n",
    "    \"\"\"\n",
    "    Recursively get all documents from `base_dir`\n",
    "    :Input base_dir: base directory of documents\n",
    "    :returns out: a list of full file names of the documents\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    # check if base_dir is a proper dir\n",
    "    if not os.path.isdir(base_dir):\n",
    "        return None\n",
    "\n",
    "    for d in os.listdir(base_dir):\n",
    "        full_path = os.path.join(base_dir, d)\n",
    "        if os.path.isdir(full_path):\n",
    "            out.extend(findDocumentsRecursive(full_path))\n",
    "        else:\n",
    "            for end in (\".pdf\", \".docx\"):\n",
    "                if full_path.endswith(end):\n",
    "                    out.append(full_path)\n",
    "                    \n",
    "    #print(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "941c9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = findDocumentsRecursive(r\"D:\\CV\\original cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae729b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b60465d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = []\n",
    "with open(r\"D:\\Projects\\Untitled Folder\\skills.txt.txt\",'r') as fin:\n",
    "    skills.append(fin.readline().split(','))\n",
    "\n",
    "#print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73ba56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocxText(filename):\n",
    "    \"\"\"\n",
    "    Get the text from a docx file\n",
    "    :param filename: docx file\n",
    "    :returns fullText: text of file\n",
    "    \"\"\"\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        txt = para.text\n",
    "        fullText.append(txt)\n",
    "    return \"\\n\".join(fullText)\n",
    "\n",
    "\n",
    "def getPDFText(filename, parser):\n",
    "    \"\"\"\n",
    "    Get the text from a pdf file\n",
    "    :param filename: pdf file\n",
    "    :param parser: pdf parser\n",
    "    :returns fullText: text of file\n",
    "    \"\"\"\n",
    "    raw = parser.from_file(filename)\n",
    "    #print(\"Raw is \", raw)\n",
    "    #print(\"Content is \", raw[\"content\"])\n",
    "    #print(\"Metadata is \", raw[\"metadata\"])\n",
    "    new_text = raw[\"content\"]\n",
    "    if \"title\" in raw[\"metadata\"]:\n",
    "        title = raw[\"metadata\"][\"title\"]\n",
    "        new_text = new_text.replace(title, \"\")\n",
    "        \n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "965de52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDocumentIntoSpacy(f, parser, spacy_nlp):\n",
    "    \"\"\"\n",
    "    Convert file into spacy Document\n",
    "    :param f: filename\n",
    "    :param parser: pdf_parser\n",
    "    :param spacy_nlp: nlp model\n",
    "    :returns nlp_doc: nlp doc\n",
    "    :returns new_text: text of file\n",
    "    \"\"\"\n",
    "    if f.endswith(\".pdf\"):\n",
    "        new_text = getPDFText(f, parser)\n",
    "    elif f.endswith(\".docx\"):\n",
    "        new_text = getDocxText(f)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "    new_text = re.sub(\"\\n{3,}\", \"\\n\", new_text)  #Replaces 3 empty lines with 1\n",
    "    new_text = str(bytes(new_text, \"utf-8\").replace(b\"\\xe2\\x80\\x93\", b\"\"), \"utf-8\")      #Replaces - in the text with \"\"\n",
    "    \n",
    "    #print(spacy_nlp(new_text))\n",
    "    #print(\"\\n\",new_text)\n",
    "    # convert to spacy doc\n",
    "    return spacy_nlp(new_text),new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d78f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTokensAndChunks(doc):\n",
    "    \"\"\"\n",
    "    Converts a spacy doc into tokens and chunks\n",
    "    :Input doc: a SpaCy doc\n",
    "    :returns: seen_chunks_words: set of strings seen\n",
    "    :returns: all_tokens_chunks: set of all tokens and chunks found\n",
    "    \"\"\"\n",
    "    # used to test duplicate words/chunks\n",
    "    seen_chunks_words = set()\n",
    "    # collect all words/chunks\n",
    "    all_tokens_chunks = set()\n",
    "    # generate all 1-gram tokens\n",
    "    for token in doc:\n",
    "        w = token.lemma_.lower()\n",
    "        if (w not in seen_chunks_words):\n",
    "            all_tokens_chunks.add(token)\n",
    "            seen_chunks_words.add(w)\n",
    "\n",
    "    # generate all n-gram tokens\n",
    "    #print(\"\\n Doc noun is \",doc.noun_chunks)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        c = chunk.lemma_.lower()\n",
    "        #print(\"\\n Smaller chunk is\", c)\n",
    "        if (\n",
    "            len(chunk) > 1\n",
    "            and (c not in seen_chunks_words)\n",
    "        ):\n",
    "            all_tokens_chunks.add(chunk)\n",
    "            seen_chunks_words.add(c)\n",
    "\n",
    "    return seen_chunks_words, all_tokens_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa9278",
   "metadata": {},
   "source": [
    "# Creating data from the fetched details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125ba4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting resume tokens and chunks...\n",
      ".................................................................................................................\n",
      " Data Populated\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting resume tokens and chunks...\")\n",
    "pdf_data = defaultdict(list)\n",
    "for p in pdfs:\n",
    "    # convert to spacy doc\n",
    "    doc, _ = loadDocumentIntoSpacy(p, parser, nlp)\n",
    "    seen_chunks_words, all_tokens_chunks = getAllTokensAndChunks(doc)\n",
    "    pdf_data[\"Category\"].append(os.path.basename(os.path.dirname(p)))\n",
    "    seen_chunks_words.update(all_tokens_chunks)\n",
    "    pdf_data[\"Resume\"].append(list(seen_chunks_words))\n",
    "    print(\".\",end =\"\")\n",
    "       \n",
    "pdf_df = pd.DataFrame(data=pdf_data)\n",
    "pdf_df[\"Resume\"] =  [' '.join(map(str, l)) for l in pdf_df[\"Resume\"]]\n",
    "print(\"\\n Data Populated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30440904",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_df.to_csv(r'D:\\Projects\\Untitled Folder\\our_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efcc8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data = pd.read_csv(r\"D:\\Projects\\Untitled Folder\\UpdatedResumeDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6994d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdf_df.append(more_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a05ee470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Resume\"][67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d29b87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9689aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_13096/1103273210.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Resume\"][i] = review\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    review = re.sub('http[s]?://\\S+', '', str(df[\"Resume\"][i]))\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-zA-Z&.]', ' ', review)\n",
    "    df[\"Resume\"][i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4162f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************* Skill reading done *************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_13096/718283567.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Review\"][i] = df[\"Review\"][i]+\" \"+concat_word\n"
     ]
    }
   ],
   "source": [
    "skills = []\n",
    "with open(\"skills.txt.txt\",'r') as f:\n",
    "   # perform file operations\n",
    "    for word in f.readline().strip().split(','):\n",
    "        word=re.sub('[^a-zA-Z]', ' ', str(word))\n",
    "        skills.append(word)\n",
    "        \n",
    "skills_updated=[]\n",
    "for word in skills:\n",
    "    new_words=word.split()\n",
    "    skills_updated.append(new_words)\n",
    "\n",
    "print('************************************* Skill reading done *************************************************************')\n",
    "\n",
    "final_words=[]\n",
    "df[\"Review\"] = ''\n",
    "for i in range(len(df)):\n",
    "    for word in skills_updated:\n",
    "        concat_word = \"\"\n",
    "        for j in word:\n",
    "            if j in df[\"Resume\"][i]:\n",
    "                concat_word = concat_word + j  \n",
    "                \n",
    "            #print(\"Concat word is \",concat_word)   \n",
    "        if concat_word != \"\":\n",
    "            final_words.append(concat_word)\n",
    "            df[\"Review\"][i] = df[\"Review\"][i]+\" \"+concat_word\n",
    "\n",
    "with open('intermediate.txt', 'w') as f:\n",
    "    for item in final_words:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312913d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd03ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "45d4736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1075, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b03f8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[\"Review\"][i]=' '.join(map(str,[i for i in list(set(df['Review'][i].split(' '))) if len(i) > 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa1e0941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data machine business intelligence march   ana...</td>\n",
       "      <td>learning spark machinelearning python language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>services    record          intelligence busin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>services runner mumbai area   platform intelli...</td>\n",
       "      <td>hadoop spark process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>google cloud platform postgraduate provide nat...</td>\n",
       "      <td>learning spark machinelearning naturallanguage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>visualizing creating intelligence software mas...</td>\n",
       "      <td>learning spark machinelearning pyspark tableau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                             Resume  \\\n",
       "0  Data Engineer  data machine business intelligence march   ana...   \n",
       "1  Data Engineer  services    record          intelligence busin...   \n",
       "2  Data Engineer  services runner mumbai area   platform intelli...   \n",
       "3  Data Engineer  google cloud platform postgraduate provide nat...   \n",
       "4  Data Engineer  visualizing creating intelligence software mas...   \n",
       "\n",
       "                                              Review  \n",
       "0     learning spark machinelearning python language  \n",
       "1                                                     \n",
       "2                               hadoop spark process  \n",
       "3  learning spark machinelearning naturallanguage...  \n",
       "4  learning spark machinelearning pyspark tableau...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a94acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkp.to_csv(r'D:\\Projects\\Untitled Folder\\resume_data.csv',index=False)\n",
    "df.to_csv(r'D:\\Projects\\Untitled Folder\\no_duplicates_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e60d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"Category\",\"Review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "120e9022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['Review'][i] = df['Review'][i] + \" \" + df['Review'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab46aadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning spark machinelearning python language learning spark machinelearning python language'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2a3835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_13096/3429870898.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rating\"][i] = rating\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Rating'] = 0\n",
    "for i in range(len(df)):\n",
    "    count = 0\n",
    "    text = df[\"Review\"][i].split()\n",
    "    for word in range(len(text)):\n",
    "        if text[word] in skills:\n",
    "            count+=1\n",
    "    cal = (count/len(skills)) * 7\n",
    "    if (cal) > 5:\n",
    "        rating = 5\n",
    "    elif cal < 1:\n",
    "        rating = 1\n",
    "    else:\n",
    "        rating = cal\n",
    "    df[\"Rating\"][i] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdf72d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c866c082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'Review', 'Rating'], dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[Category', 'Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9fae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5fc8c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\Projects\\Untitled Folder\\final_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0fb52773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Projects\\Untitled Folder\\final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "572fb3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Engineer', 'Data Science', 'HR', 'Advocate', 'Arts',\n",
       "       'Web Designing', 'Mechanical Engineer', 'Sales',\n",
       "       'Health and fitness', 'Civil Engineer', 'Java Developer',\n",
       "       'Business Analyst', 'SAP Developer', 'Automation Testing',\n",
       "       'Electrical Engineering', 'Operations Manager', 'Python Developer',\n",
       "       'DevOps Engineer', 'Network Security Engineer', 'PMO', 'Database',\n",
       "       'Hadoop', 'ETL Developer', 'DotNet Developer', 'Blockchain',\n",
       "       'Testing'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab8dd554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skills_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dacf51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=['Data Engineer', 'Data Science', 'HR', 'Advocate', 'Arts',\n",
    "       'Web Designing', 'Mechanical Engineer', 'Sales',\n",
    "       'Health and fitness', 'Civil Engineer', 'Java Developer',\n",
    "       'Business Analyst', 'SAP Developer', 'Automation Testing',\n",
    "       'Electrical Engineering', 'Operations Manager', 'Python Developer',\n",
    "       'DevOps Engineer', 'Network Security Engineer', 'PMO', 'Database',\n",
    "       'Hadoop', 'ETL Developer', 'DotNet Developer', 'Blockchain',\n",
    "       'Testing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875365a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
