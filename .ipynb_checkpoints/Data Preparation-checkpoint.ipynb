{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "352fb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import gensim\n",
    "import sys\n",
    "import subprocess\n",
    "import json\n",
    "import tika\n",
    "import re\n",
    "import docx\n",
    "from spacy.language import Language\n",
    "from tika import parser\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8247d6f",
   "metadata": {},
   "source": [
    "# Function to load Default spacy nlp model and starting the tika server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "27f59d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDefaultNLP(is_big: bool = True):\n",
    "    \"\"\"\n",
    "    Function to load the default SpaCy nlp model into nlp\n",
    "    :Input is_big: if True, uses a large vocab set, else a small one\n",
    "    :returns: nlp: a SpaCy nlp model\n",
    "    \"\"\"\n",
    "\n",
    "    @Language.component(\"segment_on_newline\")\n",
    "    def segment_on_newline(doc):\n",
    "        for token in doc[:-1]:\n",
    "            if token.text.endswith(\"\\n\"):\n",
    "                doc[token.i + 1].is_sent_start = True\n",
    "        return doc\n",
    "\n",
    "    if is_big:\n",
    "        nlp = spacy.load(\"en_core_web_lg\")\n",
    "    else:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    Language.component(\"segment_on_newline\",func=segment_on_newline)\n",
    "    nlp.add_pipe(\"segment_on_newline\",before=\"parser\")\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "d06ddd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.lang.en.English object at 0x000001CD048FF550>\n"
     ]
    }
   ],
   "source": [
    "nlp = loadDefaultNLP(False)\n",
    "tika.initVM()\n",
    "from tika import parser\n",
    "print(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401f312",
   "metadata": {},
   "source": [
    "# Get PDF/Doc names from the input directories where resumes are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "17f87b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDocumentsRecursive(base_dir):\n",
    "    \"\"\"\n",
    "    Recursively get all documents from `base_dir`\n",
    "    :Input base_dir: base directory of documents\n",
    "    :returns out: a list of full file names of the documents\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    # check if base_dir is a proper dir\n",
    "    if not os.path.isdir(base_dir):\n",
    "        return None\n",
    "\n",
    "    for d in os.listdir(base_dir):\n",
    "        full_path = os.path.join(base_dir, d)\n",
    "        if os.path.isdir(full_path):\n",
    "            out.extend(findDocumentsRecursive(full_path))\n",
    "        else:\n",
    "            for end in (\".pdf\", \".docx\"):\n",
    "                if full_path.endswith(end):\n",
    "                    out.append(full_path)\n",
    "                    \n",
    "    #print(out)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "941c9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = findDocumentsRecursive(r\"D:\\CV\\original cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "ae729b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "b60465d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = []\n",
    "with open(r\"D:\\Projects\\Untitled Folder\\skills.txt.txt\",'r') as fin:\n",
    "    skills.append(fin.readline().split(','))\n",
    "\n",
    "#print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "73ba56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocxText(filename):\n",
    "    \"\"\"\n",
    "    Get the text from a docx file\n",
    "    :param filename: docx file\n",
    "    :returns fullText: text of file\n",
    "    \"\"\"\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        txt = para.text\n",
    "        fullText.append(txt)\n",
    "    return \"\\n\".join(fullText)\n",
    "\n",
    "\n",
    "def getPDFText(filename, parser):\n",
    "    \"\"\"\n",
    "    Get the text from a pdf file\n",
    "    :param filename: pdf file\n",
    "    :param parser: pdf parser\n",
    "    :returns fullText: text of file\n",
    "    \"\"\"\n",
    "    raw = parser.from_file(filename)\n",
    "    #print(\"Raw is \", raw)\n",
    "    #print(\"Content is \", raw[\"content\"])\n",
    "    #print(\"Metadata is \", raw[\"metadata\"])\n",
    "    new_text = raw[\"content\"]\n",
    "    if \"title\" in raw[\"metadata\"]:\n",
    "        title = raw[\"metadata\"][\"title\"]\n",
    "        new_text = new_text.replace(title, \"\")\n",
    "        \n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "965de52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDocumentIntoSpacy(f, parser, spacy_nlp):\n",
    "    \"\"\"\n",
    "    Convert file into spacy Document\n",
    "    :param f: filename\n",
    "    :param parser: pdf_parser\n",
    "    :param spacy_nlp: nlp model\n",
    "    :returns nlp_doc: nlp doc\n",
    "    :returns new_text: text of file\n",
    "    \"\"\"\n",
    "    if f.endswith(\".pdf\"):\n",
    "        new_text = getPDFText(f, parser)\n",
    "    elif f.endswith(\".docx\"):\n",
    "        new_text = getDocxText(f)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "    new_text = re.sub(\"\\n{3,}\", \"\\n\", new_text)  #Replaces 3 empty lines with 1\n",
    "    new_text = str(bytes(new_text, \"utf-8\").replace(b\"\\xe2\\x80\\x93\", b\"\"), \"utf-8\")      #Replaces - in the text with \"\"\n",
    "    \n",
    "    #print(spacy_nlp(new_text))\n",
    "    #print(\"\\n\",new_text)\n",
    "    # convert to spacy doc\n",
    "    return spacy_nlp(new_text),new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "47d78f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTokensAndChunks(doc):\n",
    "    \"\"\"\n",
    "    Converts a spacy doc into tokens and chunks\n",
    "    :Input doc: a SpaCy doc\n",
    "    :returns: seen_chunks_words: set of strings seen\n",
    "    :returns: all_tokens_chunks: set of all tokens and chunks found\n",
    "    \"\"\"\n",
    "    # used to test duplicate words/chunks\n",
    "    seen_chunks_words = set()\n",
    "    # collect all words/chunks\n",
    "    all_tokens_chunks = set()\n",
    "    # generate all 1-gram tokens\n",
    "    for token in doc:\n",
    "        w = token.lemma_.lower()\n",
    "        if (w not in seen_chunks_words):\n",
    "            all_tokens_chunks.add(token)\n",
    "            seen_chunks_words.add(w)\n",
    "\n",
    "    # generate all n-gram tokens\n",
    "    #print(\"\\n Doc noun is \",doc.noun_chunks)\n",
    "    for chunk in doc.noun_chunks:\n",
    "        c = chunk.lemma_.lower()\n",
    "        #print(\"\\n Smaller chunk is\", c)\n",
    "        if (\n",
    "            len(chunk) > 1\n",
    "            and (c not in seen_chunks_words)\n",
    "        ):\n",
    "            all_tokens_chunks.add(chunk)\n",
    "            seen_chunks_words.add(c)\n",
    "\n",
    "    return seen_chunks_words, all_tokens_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa9278",
   "metadata": {},
   "source": [
    "# Creating data from the fetched details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "125ba4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting resume tokens and chunks...\n",
      ".................................................................................................................\n",
      " Data Populated\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting resume tokens and chunks...\")\n",
    "pdf_data = defaultdict(list)\n",
    "for p in pdfs:\n",
    "    # convert to spacy doc\n",
    "    doc, _ = loadDocumentIntoSpacy(p, parser, nlp)\n",
    "    seen_chunks_words, all_tokens_chunks = getAllTokensAndChunks(doc)\n",
    "    pdf_data[\"Category\"].append(os.path.basename(os.path.dirname(p)))\n",
    "    seen_chunks_words.update(all_tokens_chunks)\n",
    "    pdf_data[\"Resume\"].append(list(seen_chunks_words))\n",
    "    print(\".\",end =\"\")\n",
    "       \n",
    "pdf_df = pd.DataFrame(data=pdf_data)\n",
    "pdf_df[\"Resume\"] =  [' '.join(map(str, l)) for l in pdf_df[\"Resume\"]]\n",
    "print(\"\\n Data Populated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "30440904",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_df.to_csv(r'D:\\Projects\\Untitled Folder\\our_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "efcc8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data = pd.read_csv(r\"D:\\Projects\\Untitled Folder\\UpdatedResumeDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "c6994d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdf_df.append(more_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "b3dc1313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Resume\"][67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "af4a858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "9689aa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8716/1103273210.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Resume\"][i] = review\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    review = re.sub('http[s]?://\\S+', '', str(df[\"Resume\"][i]))\n",
    "    review = review.lower()\n",
    "    review = re.sub('[^a-zA-Z&.]', ' ', review)\n",
    "    df[\"Resume\"][i] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "b4162f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************* Skill reading done *************************************************************\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U1')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8716/3027118247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconcat_word\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mfinal_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Review\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Review\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconcat_word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'intermediate.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('float64'), dtype('<U1')) -> None"
     ]
    }
   ],
   "source": [
    "skills = []\n",
    "with open(\"skills.txt.txt\",'r') as f:\n",
    "   # perform file operations\n",
    "    for word in f.readline().strip().split(','):\n",
    "        word=re.sub('[^a-zA-Z]', ' ', str(word))\n",
    "        skills.append(word)\n",
    "        \n",
    "skills_updated=[]\n",
    "for word in skills:\n",
    "    new_words=word.split()\n",
    "    skills_updated.append(new_words)\n",
    "\n",
    "print('************************************* Skill reading done *************************************************************')\n",
    "\n",
    "final_words=[]\n",
    "df[\"Review\"] = ''\n",
    "for i in range(len(df)):\n",
    "    for word in skills_updated:\n",
    "        concat_word = \"\"\n",
    "        for j in word:\n",
    "            if j in df[\"Resume\"][i]:\n",
    "                concat_word = concat_word + j  \n",
    "                \n",
    "            #print(\"Concat word is \",concat_word)   \n",
    "        if concat_word != \"\":\n",
    "            final_words.append(concat_word)\n",
    "            df[\"Review\"][i] = df[\"Review\"][i]+\" \"+concat_word\n",
    "\n",
    "with open('intermediate.txt', 'w') as f:\n",
    "    for item in final_words:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "013472e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Category\",\"Resume\",\"Review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "7c5fafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "5bcd7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df[\"Review\"][i]=' '.join(map(str,[i for i in list(set(df['Review'][i].split(' '))) if len(i) > 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "39ebb2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data medical linkedin   months   month institu...</td>\n",
       "      <td>data tech cprogramminglanguage api machinelear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data an linkedin scientist    adept university...</td>\n",
       "      <td>data tech manage managementexperience microsof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data to linkedin fruitwala a data engineer up ...</td>\n",
       "      <td>googleapi data lean center api shell services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>my education linkedin analysis implement boo...</td>\n",
       "      <td>data flow elastic analysis python eve start an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data desktop linkedin records   month visualiz...</td>\n",
       "      <td>data you microsoft python and desktop desk exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                             Resume  \\\n",
       "0  Data Engineer  data medical linkedin   months   month institu...   \n",
       "1  Data Engineer  data an linkedin scientist    adept university...   \n",
       "2  Data Engineer  data to linkedin fruitwala a data engineer up ...   \n",
       "3  Data Engineer    my education linkedin analysis implement boo...   \n",
       "4  Data Engineer  data desktop linkedin records   month visualiz...   \n",
       "\n",
       "                                              Review  \n",
       "0  data tech cprogramminglanguage api machinelear...  \n",
       "1  data tech manage managementexperience microsof...  \n",
       "2  googleapi data lean center api shell services ...  \n",
       "3  data flow elastic analysis python eve start an...  \n",
       "4  data you microsoft python and desktop desk exp...  "
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "ab14c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkp.to_csv(r'D:\\Projects\\Untitled Folder\\resume_data.csv',index=False)\n",
    "df.to_csv(r'D:\\Projects\\Untitled Folder\\no_duplicates_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "730ad490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"Category\",\"Review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476aa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Review\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a89d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "c1fcfdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8716/3392804364.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Rating\"][i] = rating\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['Rating'] = 0\n",
    "for i in range(len(df)):\n",
    "    count = 0\n",
    "    text = df[\"Review\"][i].split()\n",
    "    for word in range(len(text)):\n",
    "        if text[word] in skills:\n",
    "            count+=1\n",
    "    cal = (count/len(skills)) * 200\n",
    "    if (cal) > 5:\n",
    "        rating = 5\n",
    "    elif cal < 1:\n",
    "        rating = 1\n",
    "    else:\n",
    "        rating = cal\n",
    "    df[\"Rating\"][i] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "3f793185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data tech cprogramminglanguage api machinelear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data tech manage managementexperience microsof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>googleapi data lean center api shell services ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data flow elastic analysis python eve start an...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data you microsoft python and desktop desk exp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                             Review  Rating\n",
       "0  Data Engineer  data tech cprogramminglanguage api machinelear...       1\n",
       "1  Data Engineer  data tech manage managementexperience microsof...       1\n",
       "2  Data Engineer  googleapi data lean center api shell services ...       1\n",
       "3  Data Engineer  data flow elastic analysis python eve start an...       4\n",
       "4  Data Engineer  data you microsoft python and desktop desk exp...       2"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "3c5b34b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    323\n",
       "1    321\n",
       "3    205\n",
       "2    133\n",
       "4     93\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7983a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "5fc8c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'D:\\Projects\\Untitled Folder\\final_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "34e8bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Projects\\Untitled Folder\\final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "b8761c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data tech cprogramminglanguage api machinelear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data tech manage managementexperience microsof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>googleapi data lean center api shell services ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data flow elastic analysis python eve start an...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>data you microsoft python and desktop desk exp...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category                                             Review  Rating\n",
       "0  Data Engineer  data tech cprogramminglanguage api machinelear...       1\n",
       "1  Data Engineer  data tech manage managementexperience microsof...       1\n",
       "2  Data Engineer  googleapi data lean center api shell services ...       1\n",
       "3  Data Engineer  data flow elastic analysis python eve start an...       4\n",
       "4  Data Engineer  data you microsoft python and desktop desk exp...       2"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8dd554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ba7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b816e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c9005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc471b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95477e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08905fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
